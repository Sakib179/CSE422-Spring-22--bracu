{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.7"},"colab":{"provenance":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"lzS89dStTfrQ"},"source":["## CSE 422 Introduction to Data Preprocessing\n","---\n","\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"cAhCkRL_SscW"},"source":["### What are the advantages of preprocessing the data before applying on machine learning algorithm?\n","\n","\"The biggest advantage of pre-processing in ML is to improve **generalizablity** of your model. Data for any ML application is collected through some ‘sensors’. These sensors can be physical devices, instruments, software programs such as web crawlers, manual surveys, etc. Due to hardware malfunctions, software glitches, instrument failures, amd human errors, noise and erroneous information may creep in that can severely affect the performance of your model. Apart from **noise**, there are several **redundant information** that needs to be removed. For e.g. while predicting whether it rains tomorrow or not, age of the person is irrelevant. In terms of text processing, there are several stop words that may be redundant for the analysis. Lastly, there may be several **outliers** present in your data, due to the way data is collected that may need to be removed to improve the performance of the classifiers.\"\n","                                    \n","                                            -Shehroz Khan, ML Researcher, Postdoc @U of Toronto\n"]},{"cell_type":"markdown","metadata":{"id":"0YYIQ5CNcZx-"},"source":["Some Data Preprocessing Techniques:\n","\n","* Deleting duplicate and null values\n","* Imputation for missing values\n","* Handling Categorical Features\n","* Feature Normalization/Scaling\n","* Feature Engineering\n","* Feature Selection"]},{"cell_type":"code","metadata":{"id":"gZPvqZUPTfrH","executionInfo":{"status":"ok","timestamp":1711246645747,"user_tz":-360,"elapsed":736,"user":{"displayName":"SAKIB RAYHAN YEASIN","userId":"02515015102391967297"}}},"source":["#importing necessary libraries\n","import pandas as pd\n","import numpy as np\n"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0EvGojt9m-Yo"},"source":["#Removing Null values / Handling Missing data\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"40I_BWUeTfrS","colab":{"base_uri":"https://localhost:8080/","height":317},"outputId":"319a862d-6c9b-4c63-adee-e2bc6b0a4ff7","executionInfo":{"status":"error","timestamp":1711246646229,"user_tz":-360,"elapsed":4,"user":{"displayName":"SAKIB RAYHAN YEASIN","userId":"02515015102391967297"}}},"source":["volunteer = pd.read_csv('/content/sample_data/volunteer_opportunities.csv')\n","volunteer.head(3)"],"execution_count":2,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/content/sample_data/volunteer_opportunities.csv'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-ca7afdfff85b>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvolunteer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/sample_data/volunteer_opportunities.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mvolunteer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1736\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    857\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/sample_data/volunteer_opportunities.csv'"]}]},{"cell_type":"code","metadata":{"id":"utvR4slHUUoH","executionInfo":{"status":"aborted","timestamp":1711246646230,"user_tz":-360,"elapsed":4,"user":{"displayName":"SAKIB RAYHAN YEASIN","userId":"02515015102391967297"}}},"source":["volunteer.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RFHvAKsPaJhH","executionInfo":{"status":"aborted","timestamp":1711246646230,"user_tz":-360,"elapsed":4,"user":{"displayName":"SAKIB RAYHAN YEASIN","userId":"02515015102391967297"}}},"source":["volunteer.isnull().sum()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1mD-JfDWa_Fu"},"source":["dropping columns"]},{"cell_type":"code","metadata":{"id":"ktNVIfmZMPuT","executionInfo":{"status":"aborted","timestamp":1711246646230,"user_tz":-360,"elapsed":3,"user":{"displayName":"SAKIB RAYHAN YEASIN","userId":"02515015102391967297"}}},"source":["volunteer = volunteer.drop(['BIN', 'BBL', 'NTA'], axis = 1)\n","volunteer.shape"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QOY4Abiua72Z"},"source":["dropping rows"]},{"cell_type":"code","metadata":{"id":"66t7QR7sTfrX","executionInfo":{"status":"aborted","timestamp":1711246646231,"user_tz":-360,"elapsed":1915,"user":{"displayName":"SAKIB RAYHAN YEASIN","userId":"02515015102391967297"}}},"source":["# Check how many values are missing in the category_desc column\n","print(\"Number of rows with null values in category_desc column: \", volunteer['category_desc'].isnull().sum())\n","\n","# Subset the volunteer dataset\n","\n","volunteer_subset = volunteer[volunteer['category_desc'].notnull()]\n","\n","# Print out the shape of the subset\n","print(\"Shape after removing null values: \", volunteer_subset.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-S7J7lLOrJdJ","executionInfo":{"status":"aborted","timestamp":1711246646231,"user_tz":-360,"elapsed":1913,"user":{"displayName":"SAKIB RAYHAN YEASIN","userId":"02515015102391967297"}}},"source":["print(\"Shape of dataframe before dropping:\", volunteer.shape)\n","volunteer = volunteer.dropna(axis = 0, subset = ['category_desc'])\n","print(\"Shape after dropping:\", volunteer.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_W4nE4hGip78"},"source":["### Imputing missing Values"]},{"cell_type":"code","metadata":{"id":"IDnuRns2rWJ0","executionInfo":{"status":"aborted","timestamp":1711246646231,"user_tz":-360,"elapsed":1911,"user":{"displayName":"SAKIB RAYHAN YEASIN","userId":"02515015102391967297"}}},"source":["sales = pd.read_csv('/content/sample_data/sales.csv', index_col = ['month'])\n","sales"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-gre3DF2BOBn","executionInfo":{"status":"aborted","timestamp":1711246646231,"user_tz":-360,"elapsed":1907,"user":{"displayName":"SAKIB RAYHAN YEASIN","userId":"02515015102391967297"}}},"source":["sales.fillna(50)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WwA7m0GYBa0V","executionInfo":{"status":"aborted","timestamp":1711246646800,"user_tz":-360,"elapsed":5,"user":{"displayName":"SAKIB RAYHAN YEASIN","userId":"02515015102391967297"}}},"source":["sales = pd.read_csv('/content/sample_data/sales.csv', index_col = ['month'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"18XKg-3tDV3S","executionInfo":{"status":"aborted","timestamp":1711246646800,"user_tz":-360,"elapsed":5,"user":{"displayName":"SAKIB RAYHAN YEASIN","userId":"02515015102391967297"}}},"source":["sales[['salt']]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ugpsjd-SyEhC","executionInfo":{"status":"aborted","timestamp":1711246646800,"user_tz":-360,"elapsed":5,"user":{"displayName":"SAKIB RAYHAN YEASIN","userId":"02515015102391967297"}}},"source":["from sklearn.impute import SimpleImputer\n","\n","impute = SimpleImputer(missing_values=np.nan, strategy='mean')\n","\n","impute.fit(sales[['salt']])\n","\n","sales['salt'] = impute.transform(sales[['salt']])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7ZTXR0hT15ZH","executionInfo":{"status":"aborted","timestamp":1711246646800,"user_tz":-360,"elapsed":5,"user":{"displayName":"SAKIB RAYHAN YEASIN","userId":"02515015102391967297"}}},"source":["sales"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IHnRFvFPTfr0"},"source":["## Standardizing Data"]},{"cell_type":"markdown","metadata":{"id":"kgHgelb9RUXB"},"source":["## Feature Scaling"]},{"cell_type":"markdown","metadata":{"id":"1lcM-IuqD_XW"},"source":["## Why do we need to scale our data?\n","* If a feature’s variance is orders of magnitude more than the variance of other features, that particular feature might dominate other features in the dataset and make the estimator unable to learn from other features correctly, i.e. our learner might give more importance to features with high variance, which is not something we want happening in our model.\n","\n","The following are a few different types of Scalers:\n"]},{"cell_type":"markdown","metadata":{"id":"Sq14OVytLYu4"},"source":["**MinMax Scaler:**\n","\n","Scales values to a range between 0 and 1 if no negative values, and -1 to 1 if there are negative values present.\n","\n","$$\\frac{X - X_{min}}{X_{max} - X_{min}}$$\n","\n","where,\n","\n"," $$X\\space is\\space a\\space feature\\space value.$$\n"," $$X_{min} \\space and \\space X_{max} \\space are \\space corresponding \\space feature's \\space min \\space and \\space max \\space values. $$\n","\n","\n","**Standard Scaler:**\n","\n","$$\\frac{X - mean}{\\sigma}$$\n","where,\n","$$\\sigma = standard \\space deviation $$\n","\n","**Robust Scaler:**\n","\n","Uses statistics that are robust to outliers\n","\n","$$\\frac{X - median}{IQR}$$\n","\n","where,\n","\n","$$ IQR = Inter\\space Quartile\\space Range = Q_3 - Q_1 $$\n"]},{"cell_type":"markdown","metadata":{"id":"KQob80w1EzLr"},"source":["Sklearn library provides functions for different scalers by which we can easily scale our data."]},{"cell_type":"code","metadata":{"id":"KtHgJCq694fQ","executionInfo":{"status":"aborted","timestamp":1711246646800,"user_tz":-360,"elapsed":5,"user":{"displayName":"SAKIB RAYHAN YEASIN","userId":"02515015102391967297"}}},"source":["from sklearn.datasets import load_breast_cancer\n","from sklearn.model_selection import train_test_split\n","\n","cancer = load_breast_cancer()\n","\n","X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target,\n","                                                    random_state=1)\n","print(X_train.shape)\n","print(X_test.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nmRRRpz9973B","executionInfo":{"status":"aborted","timestamp":1711246646801,"user_tz":-360,"elapsed":6,"user":{"displayName":"SAKIB RAYHAN YEASIN","userId":"02515015102391967297"}}},"source":["from sklearn.preprocessing import MinMaxScaler\n","\n","scaler = MinMaxScaler()\n","\n","scaler.fit(X_train)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"koZK3tgWFhGp","executionInfo":{"status":"aborted","timestamp":1711246646801,"user_tz":-360,"elapsed":6,"user":{"displayName":"SAKIB RAYHAN YEASIN","userId":"02515015102391967297"}}},"source":["# transform data\n","X_train_scaled = scaler.transform(X_train)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"H-kDLXZu-YBX"},"source":["We can see that after Min-Max Scaling all the values are in the range [0,1]"]},{"cell_type":"code","metadata":{"id":"rc54JPhqF0dt","executionInfo":{"status":"aborted","timestamp":1711246646801,"user_tz":-360,"elapsed":6,"user":{"displayName":"SAKIB RAYHAN YEASIN","userId":"02515015102391967297"}}},"source":["print(\"per-feature minimum before scaling:\\n {}\".format(X_train.min(axis=0)))\n","print(\"per-feature maximum before scaling:\\n {}\".format(X_train.max(axis=0)))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cWXrV9lp-Bkp","executionInfo":{"status":"aborted","timestamp":1711246646801,"user_tz":-360,"elapsed":6,"user":{"displayName":"SAKIB RAYHAN YEASIN","userId":"02515015102391967297"}}},"source":["print(\"per-feature minimum after scaling:\\n {}\".format(\n","    X_train_scaled.min(axis=0)))\n","print(\"per-feature maximum after scaling:\\n {}\".format(\n","    X_train_scaled.max(axis=0)))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"c_7BmLE--E3w","executionInfo":{"status":"aborted","timestamp":1711246646801,"user_tz":-360,"elapsed":6,"user":{"displayName":"SAKIB RAYHAN YEASIN","userId":"02515015102391967297"}}},"source":["# transform test data\n","X_test_scaled = scaler.transform(X_test)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cvIJO2eeNp2D"},"source":["## Effect of using MinMax Scaler:"]},{"cell_type":"markdown","metadata":{"id":"cWcMT_EGGcwN"},"source":["### Accuracy without scaling"]},{"cell_type":"code","metadata":{"id":"WSA3eWpW9dlQ","executionInfo":{"status":"aborted","timestamp":1711246646801,"user_tz":-360,"elapsed":5,"user":{"displayName":"SAKIB RAYHAN YEASIN","userId":"02515015102391967297"}}},"source":["from sklearn.neighbors import KNeighborsClassifier\n","X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target,\n","                                                    random_state=0)\n","knn=KNeighborsClassifier()\n","\n","knn.fit(X_train, y_train)\n","\n","print(\"Test set accuracy: {:.2f}\".format(knn.score(X_test, y_test)))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"a3T7WMdS_X57"},"source":["### We can see that accuracy improves if we train on scaled data."]},{"cell_type":"code","metadata":{"id":"_4zKCdAA9dhi","executionInfo":{"status":"aborted","timestamp":1711246646801,"user_tz":-360,"elapsed":5,"user":{"displayName":"SAKIB RAYHAN YEASIN","userId":"02515015102391967297"}}},"source":["# preprocessing using 0-1 scaling\n","scaler = MinMaxScaler()\n","scaler.fit(X_train)\n","\n","X_train_scaled = scaler.transform(X_train)\n","\n","X_test_scaled = scaler.transform(X_test)\n","\n","#train\n","knn.fit(X_train_scaled, y_train)\n","\n","# scoring on the scaled test set\n","print(\"Scaled test set accuracy: {:.2f}\".format(\n","    knn.score(X_test_scaled, y_test)))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"THUjYQzN_S0Z"},"source":["### Effect using Standard Scaler:\n","We can see that accuracy has improved compared to the non-scaled version, but we can infer that for this problem, Standard Scaler performs worse than MinMaxScaler."]},{"cell_type":"code","metadata":{"id":"jjzSafqk-Ina","executionInfo":{"status":"aborted","timestamp":1711246646801,"user_tz":-360,"elapsed":5,"user":{"displayName":"SAKIB RAYHAN YEASIN","userId":"02515015102391967297"}}},"source":["from sklearn.preprocessing import StandardScaler\n","scaler = StandardScaler()\n","\n","#instead of using .fit() and .transform() separately, we can use .fit_transform()\n","X_scaled_d = scaler.fit_transform(X_train)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BMpuacp49del","executionInfo":{"status":"aborted","timestamp":1711246646801,"user_tz":-360,"elapsed":5,"user":{"displayName":"SAKIB RAYHAN YEASIN","userId":"02515015102391967297"}}},"source":["# preprocessing using zero mean and unit variance scaling\n","from sklearn.preprocessing import StandardScaler\n","\n","scaler = StandardScaler()\n","scaler.fit(X_train)\n","\n","X_train_scaled = scaler.transform(X_train)\n","X_test_scaled = scaler.transform(X_test)\n","\n","# learning an SVM on the scaled training data\n","knn.fit(X_train_scaled, y_train)\n","\n","# scoring on the scaled test set\n","print(\"KNN test accuracy: {:.2f}\".format(knn.score(X_test_scaled, y_test)))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"My5bgznkTfsV"},"source":["## Feature Engineering"]},{"cell_type":"markdown","metadata":{"id":"9tz87oUDTfsW"},"source":["### Encoding categorical variables - binary\n"]},{"cell_type":"code","metadata":{"id":"Ngz-ICV2TfsW","executionInfo":{"status":"aborted","timestamp":1711246646801,"user_tz":-360,"elapsed":5,"user":{"displayName":"SAKIB RAYHAN YEASIN","userId":"02515015102391967297"}}},"source":["hiking = pd.read_json('/content/sample_data/hiking.json')\n","hiking.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"M7b_JOhNWgXy","executionInfo":{"status":"aborted","timestamp":1711246646802,"user_tz":-360,"elapsed":6,"user":{"displayName":"SAKIB RAYHAN YEASIN","userId":"02515015102391967297"}}},"source":["hiking.info()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qFYXdTSpshQX","executionInfo":{"status":"aborted","timestamp":1711246646802,"user_tz":-360,"elapsed":6,"user":{"displayName":"SAKIB RAYHAN YEASIN","userId":"02515015102391967297"}}},"source":["hiking['Accessible'].unique()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1ip2DAQ5Tfsa","executionInfo":{"status":"aborted","timestamp":1711246646802,"user_tz":-360,"elapsed":6,"user":{"displayName":"SAKIB RAYHAN YEASIN","userId":"02515015102391967297"}}},"source":["from sklearn.preprocessing import LabelEncoder\n","\n","# Set up the LabelEncoder object\n","enc = LabelEncoder()\n","\n","# Apply the encoding to the \"Accessible\" column\n","hiking['Accessible_enc'] = enc.fit_transform(hiking['Accessible'])\n","\n","# Compare the two columns\n","print(hiking[['Accessible', 'Accessible_enc']].head())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"__K7zf64Dc8s"},"source":["We may also encode/map a certain class to a specific code (e.g 0/1/2) by using the `map()` function."]},{"cell_type":"code","metadata":{"id":"nUC3A0b3D-BC","executionInfo":{"status":"aborted","timestamp":1711246646802,"user_tz":-360,"elapsed":6,"user":{"displayName":"SAKIB RAYHAN YEASIN","userId":"02515015102391967297"}}},"source":["hiking['Accessible'] = hiking['Accessible'].map({'good':2,'bad':0,'average':1})"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8zfdrX8kujYK","executionInfo":{"status":"aborted","timestamp":1711246646802,"user_tz":-360,"elapsed":6,"user":{"displayName":"SAKIB RAYHAN YEASIN","userId":"02515015102391967297"}}},"source":["volunteer = pd.read_csv('/content/sample_data/volunteer_opportunities.csv')\n","volunteer.head(3)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SNCEXjltTfsf"},"source":["### Encoding categorical variables - one-hot encoding"]},{"cell_type":"code","metadata":{"id":"adGWJrRWu3c_","executionInfo":{"status":"aborted","timestamp":1711246646803,"user_tz":-360,"elapsed":7,"user":{"displayName":"SAKIB RAYHAN YEASIN","userId":"02515015102391967297"}}},"source":["volunteer.info()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NyPtPelkuzdb","executionInfo":{"status":"aborted","timestamp":1711246646803,"user_tz":-360,"elapsed":7,"user":{"displayName":"SAKIB RAYHAN YEASIN","userId":"02515015102391967297"}}},"source":["volunteer['category_desc'].unique()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9MfAn127Tfsg","executionInfo":{"status":"aborted","timestamp":1711246646803,"user_tz":-360,"elapsed":7,"user":{"displayName":"SAKIB RAYHAN YEASIN","userId":"02515015102391967297"}}},"source":["# Transform the category_desc column\n","category_enc = pd.get_dummies(volunteer['category_desc'])\n","\n","# Take a look at the encoded columns\n","category_enc.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"smExDPZxyNKx","executionInfo":{"status":"aborted","timestamp":1711246646803,"user_tz":-360,"elapsed":7,"user":{"displayName":"SAKIB RAYHAN YEASIN","userId":"02515015102391967297"}}},"source":["volunteer['category_desc'].head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4UkVypd11JW-"},"source":["##Feature Engineering"]},{"cell_type":"markdown","metadata":{"id":"4O_bdBq3qaAB"},"source":["### Engineering numerical features - by taking an average\n","\n","Suppose we have multiple features each of which contains time taken for each runner to complete a lap. We can reduce the dimensionality of our dataset (reduce the number of features) by averaging(mean) the time taken of each run."]},{"cell_type":"code","metadata":{"id":"MzqqMxxTqeh1","executionInfo":{"status":"aborted","timestamp":1711246646803,"user_tz":-360,"elapsed":7,"user":{"displayName":"SAKIB RAYHAN YEASIN","userId":"02515015102391967297"}}},"source":["running_times_5k = pd.DataFrame([['Sue', 20.1, 18.5, 19.6, 20.3, 18.3], ['Mark', 16.5, 17.1, 16.9, 17.6, 17.3], ['Sean', 23.5, 25.1, 25.2, 24.6, 23.9], ['Erin', 21.7, 21.1, 20.9, 22.1, 22.2], ['Jenny', 25.8, 27.1, 26.1, 26.7, 26.9], ['Russell', 30.9, 29.6, 31.4, 30.4, 29.9]])\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"A_7HWiUcqvz9","executionInfo":{"status":"aborted","timestamp":1711246646803,"user_tz":-360,"elapsed":7,"user":{"displayName":"SAKIB RAYHAN YEASIN","userId":"02515015102391967297"}}},"source":["running_times_5k.columns =  ['name', 'run1', 'run2', 'run3', 'run4', 'run5']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_nwf3WPJzjhX","executionInfo":{"status":"aborted","timestamp":1711246646803,"user_tz":-360,"elapsed":7,"user":{"displayName":"SAKIB RAYHAN YEASIN","userId":"02515015102391967297"}}},"source":["running_times_5k"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1eBFPPW4qkue","executionInfo":{"status":"aborted","timestamp":1711246646803,"user_tz":-360,"elapsed":7,"user":{"displayName":"SAKIB RAYHAN YEASIN","userId":"02515015102391967297"}}},"source":["# Create a list of the columns to average\n","run_columns = [\"run1\", \"run2\", \"run3\", \"run4\", \"run5\"]\n","\n","# Use apply to create a mean column\n","running_times_5k[\"mean\"] = running_times_5k.apply(lambda row: row[run_columns].mean(), axis=1)\n","\n","# Take a look at the results\n","print(running_times_5k)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GndB_JOYTfss"},"source":["### Engineering numerical features - datetime\n","\n","We are extracting the start_date_month from the `date_time` format which we can use later to input into our learner/model/algorithm. This feature will be much more meaningful for the learner compared to the `date_time` format."]},{"cell_type":"code","metadata":{"id":"gkQQ7qtl3kiP","executionInfo":{"status":"aborted","timestamp":1711246646803,"user_tz":-360,"elapsed":7,"user":{"displayName":"SAKIB RAYHAN YEASIN","userId":"02515015102391967297"}}},"source":["volunteer[\"start_date_date\"]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"h_qSQbTLTfst","executionInfo":{"status":"aborted","timestamp":1711246646803,"user_tz":-360,"elapsed":7,"user":{"displayName":"SAKIB RAYHAN YEASIN","userId":"02515015102391967297"}}},"source":["# First, convert string column to date column\n","volunteer[\"start_date_converted\"] = pd.to_datetime(volunteer[\"start_date_date\"])\n","\n","# Extract just the month from the converted column\n","volunteer[\"start_date_month\"] = volunteer[\"start_date_converted\"].apply(lambda row: row.month)\n","\n","# Take a look at the converted and new month columns\n","volunteer[['start_date_converted', 'start_date_month']].head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hjQMrkorTfs9"},"source":["## Feature Selection"]},{"cell_type":"markdown","metadata":{"id":"762jMLqRTfs_"},"source":["### Selecting relevant features\n","\n","Sometimes certain circumstances arise that we have a lot of features in our dataset, but from our prior/domain knowledge we know that certain features might not be too important. In such cases we may want to drop those irrelevant features.\n","\n"]},{"cell_type":"code","metadata":{"id":"wG2LXzDXTftA","executionInfo":{"status":"aborted","timestamp":1711246646803,"user_tz":-360,"elapsed":6,"user":{"displayName":"SAKIB RAYHAN YEASIN","userId":"02515015102391967297"}}},"source":["# Create a list of redundant column names to drop\n","to_drop = [\"category_desc\", \"created_date\", \"locality\", \"region\", \"vol_requests\"]\n","\n","# Drop those columns from the dataset\n","volunteer_subset = volunteer.drop(to_drop, axis=1)\n","\n","# Print out the head of the new dataset\n","volunteer_subset.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZjiT5OVhTftE"},"source":["### Checking for correlated features\n","\n","We may use the following heatmap to find out the correlation between each of the features in a dataset. If a certain feature is highly correlated with more than one feature, we may choose to drop that feature (in this case it is *flavanoids*) because it will affect our model in a similar way as the other two features (and thus will prove to redundant). Correlation between two features may be found using the color gradient shown on the right."]},{"cell_type":"code","metadata":{"id":"cwJFgFcKM9hM","executionInfo":{"status":"aborted","timestamp":1711246646804,"user_tz":-360,"elapsed":7,"user":{"displayName":"SAKIB RAYHAN YEASIN","userId":"02515015102391967297"}}},"source":["from sklearn.datasets import load_wine\n","\n","wine = load_wine()\n","wine_df = pd.DataFrame( wine['data'], columns=wine['feature_names'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jICUTyA3Od1P","executionInfo":{"status":"aborted","timestamp":1711246646804,"user_tz":-360,"elapsed":7,"user":{"displayName":"SAKIB RAYHAN YEASIN","userId":"02515015102391967297"}}},"source":["wine_df.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zbAXIHtA5V_C","executionInfo":{"status":"aborted","timestamp":1711246646804,"user_tz":-360,"elapsed":7,"user":{"displayName":"SAKIB RAYHAN YEASIN","userId":"02515015102391967297"}}},"source":["wine_corr = wine_df.corr()\n","wine_corr"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7xQH6KiQTftH","executionInfo":{"status":"aborted","timestamp":1711246646804,"user_tz":-360,"elapsed":7,"user":{"displayName":"SAKIB RAYHAN YEASIN","userId":"02515015102391967297"}}},"source":["import seaborn as sns\n","\n","sns.heatmap(wine_corr, cmap = 'YlGnBu')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"daUq6EAegBX2","executionInfo":{"status":"aborted","timestamp":1711246646804,"user_tz":-360,"elapsed":7,"user":{"displayName":"SAKIB RAYHAN YEASIN","userId":"02515015102391967297"}}},"source":["# Take a minute to find the column where the correlation value is greater than 0.75 at least twice\n","to_drop = 'flavanoids'\n","\n","# Drop that column from the DataFrame\n","wine_df = wine_df.drop(to_drop, axis=1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JuhnDE8qKNfG"},"source":["## **Summary:**\n","\n","Basic Pipeline for solving a ML project:\n","\n","1. Read in Dataset\n","\n","2. Get to know your dataset using data vizualisation and other techniques\n","\n","3. Preprocess your dataset:\n","\n","  * remove/impute null values\n","  * remove outliers\n","  * feature scaling\n","  * feature engineering\n","  * feature selection\n","\n","4. train/test split\n","5. choose and build (number of) machine learning algorithm\n","5. train model on training data\n","6. make prediction on test data\n","7. evaluate performance on test data\n","8. visualization of your results\n","\n"]},{"cell_type":"markdown","metadata":{"id":"_6GTCKdCc6H7"},"source":["---\n","."]},{"cell_type":"markdown","metadata":{"id":"tckKAeXvTTNV"},"source":["."]},{"cell_type":"markdown","metadata":{"id":"hmoIM5twTVbz"},"source":["**Reference**\n","\n","\n","* Müller Andreas Christian, and Sarah Guido. Introduction to Machine Learning with Python a Guide for Data Scientists. OReilly, 2018.\n","\n","* DataCamp Python Course"]}]}